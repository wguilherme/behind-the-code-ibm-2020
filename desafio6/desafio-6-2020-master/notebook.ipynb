{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MARATONA BEHIND THE CODE 2020\n",
    "\n",
    "## DESAFIO 6 - LIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dos conjuntos de dados em formato .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-check-certificate --content-disposition https://raw.githubusercontent.com/vanderlei-test/dataset-3/master/training_dataset.csv\n",
    "df_training_dataset = pd.read_csv(r'training_dataset.csv')\n",
    "df_training_dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sobre o arquivo \"training_dataset.csv\", temos algumas informações gerais sobre os usuários da plataforma:\n",
    "\n",
    "**id**\n",
    "\n",
    "**graduacao**\n",
    "\n",
    "**universidade**\n",
    "\n",
    "**profissao**\n",
    "\n",
    "**organizacao**\n",
    "\n",
    "**pretende_fazer_cursos_lit**\n",
    "\n",
    "**interesse_mba_lit**\n",
    "\n",
    "**importante_ter_certificado**\n",
    "\n",
    "**horas_semanais_estudo**\n",
    "\n",
    "**como_conheceu_lit**\n",
    "\n",
    "**total_modulos**\n",
    "\n",
    "**modulos_iniciados**\n",
    "\n",
    "**modulos_finalizados**\n",
    "\n",
    "**certificados**\n",
    "\n",
    "**categoria**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_dataset.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Detalhamento do desafio: classificação multiclasse\n",
    "\n",
    "Este é um desafio cujo objetivo de negócio é a segmentação dos usuários de uma plataforma de ensino. Para tal, podemos utilizar duas abordagens: aprendizado de máquina supervisionado (classificação) ou não-supervisionado (clustering). Neste desafio será aplicada a classificação, pois é disponível um dataset já com \"labels\", ou em outras palavras, já com exemplos de dados juntamente com a variável alvo.\n",
    "\n",
    "Na biblioteca scikit-learn temos diversos algoritmos para classificação. O participante é livre para utilizar o framework que desejar para completar esse desafio.\n",
    "\n",
    "Neste notebook será mostrado um exeplo de uso do algoritmo \"Decision Tree\" para classificar parte dos estudantes em seis diferentes perfís."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção!\n",
    "\n",
    "A coluna-alvo neste desafio é a coluna ``categoria``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processando o dataset antes do treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo todas as linhas que possuem algum valor nulos em determinadas colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando o método Pandas **DataFrame.dropna()** você pode remover todas as linhas nulas do dataset.\n",
    "\n",
    "Docs: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo os dados ausentes do conjunto de dados antes da primeira transformação (df)\n",
    "print(\"Valores nulos no df_training_dataset antes da transformação DropNA: \\n\\n{}\\n\".format(df_training_dataset.isnull().sum(axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a função para deletar todas as linhas com valor NaN na coluna ``certificados'' e ``total_modulos'':\n",
    "df_training_dataset = df_training_dataset.dropna(axis='index', how='any', subset=['certificados', 'total_modulos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exibindo os dados ausentes do conjunto de dados após a primeira transformação (df)\n",
    "print(\"Valores nulos no df_training_dataset após a transformação DropNA: \\n\\n{}\\n\".format(df_training_dataset.isnull().sum(axis = 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processando valores NaN com o SimpleImputer do sklearn\n",
    "\n",
    "Para os valores NaN, usaremos a substituição pela constante 0 como **exemplo**.\n",
    "\n",
    "Você pode escolher a estratégia que achar melhor para tratar os valores nulos :)\n",
    "\n",
    "Docs: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html?highlight=simpleimputer#sklearn.impute.SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "impute_zeros = SimpleImputer(\n",
    "    missing_values=np.nan,\n",
    "    strategy='constant',\n",
    "    fill_value=0,\n",
    "    verbose=0,\n",
    "    copy=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo os dados ausentes do conjunto de dados antes da primeira transformação (df)\n",
    "print(\"Valores nulos no df_training_dataset antes da transformação SimpleImputer: \\n\\n{}\\n\".format(df_training_dataset.isnull().sum(axis = 0)))\n",
    "\n",
    "# Aplicando a transformação ``SimpleImputer`` no conjunto de dados base\n",
    "impute_zeros.fit(X=df_training_dataset)\n",
    "\n",
    "# Reconstruindo um Pandas DataFrame com os resultados\n",
    "df_training_dataset_imputed = pd.DataFrame.from_records(\n",
    "    data=impute_zeros.transform(\n",
    "        X=df_training_dataset\n",
    "    ),\n",
    "    columns=df_training_dataset.columns\n",
    ")\n",
    "\n",
    "# Exibindo os dados ausentes do conjunto de dados após a primeira transformação (df)\n",
    "print(\"Valores nulos no df_training_dataset após a transformação SimpleImputer: \\n\\n{}\\n\".format(df_training_dataset_imputed.isnull().sum(axis = 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminando colunas indesejadas\n",
    "\n",
    "Vamos **demonstrar** abaixo como usar o método **DataFrame.drop()**.\n",
    "\n",
    "Docs: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_dataset_imputed.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_dataset_rmcolumns = df_training_dataset_imputed.drop(columns=['id', 'graduacao', 'universidade', 'organizacao', 'como_conheceu_lit'], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_dataset_rmcolumns.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção!\n",
    "\n",
    "As colunas removidas acima são apenas para fim de exemplo, você pode usar as colunas que quiser e inclusive criar novas colunas com dados que achar importantes!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de de variáveis categóricas\n",
    "\n",
    "Como mencionado antes, os computadores não são bons com variáveis \"categóricas\" (ou strings).\n",
    "\n",
    "Dado uma coluna com variável categórica, o que podemos realizar é a codificação dessa coluna em múltiplas colunas contendo variáveis binárias. Esse processo é chamado de \"one-hot-encoding\" ou \"dummy encoding\". Se você não é familiarizado com esses termos, você pode pesquisar mais sobre isso na internet :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratando variáveis categóricas com o método Pandas ``get_dummies()''\n",
    "df_training = pd.get_dummies(df_training_dataset_rmcolumns, columns=['profissao'])\n",
    "df_training.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção!\n",
    "\n",
    "A coluna **categoria** deve ser mantida como uma string. Você não precisa processar/codificar a variável-alvo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando um classificador com base em uma árvore de decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionando FEATURES e definindo a variável TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_training[\n",
    "    [\n",
    "        'pretende_fazer_cursos_lit', 'interesse_mba_lit',\n",
    "        'importante_ter_certificado', 'horas_semanais_estudo', 'total_modulos',\n",
    "        'modulos_iniciados', 'modulos_finalizados', 'certificados',\n",
    "        'profissao_0', 'profissao_Advogado', 'profissao_Analista',\n",
    "        'profissao_Analista Senior', 'profissao_Assessor',\n",
    "        'profissao_Coordenador', 'profissao_Diretor', 'profissao_Engenheiro',\n",
    "        'profissao_Gerente', 'profissao_Outros', 'profissao_SEM EXPERIÊNCIA',\n",
    "        'profissao_Supervisor', 'profissao_Sócio/Dono/Proprietário'\n",
    "    ]\n",
    "]\n",
    "target = df_training['categoria']  ## NÃO TROQUE O NOME DA VARIÁVEL TARGET."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo nosso conjunto de dados em conjuntos de treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=133)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando uma árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método para creacion de modelos basados en arbol de desición\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "dtc = DecisionTreeClassifier(max_depth=15).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo previsões na amostra de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dtc.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisando a qualidade do modelo através da matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=None, normalize=True):\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['parfil1', 'perfil2', 'perfil3', 'perfil4', 'perfil5', 'perfil6'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring dos dados necessários para entregar a solução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como entrega da sua solução, esperamos os resultados classificados no seguinte dataset chamado \"to_be_scored.csv\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download da \"folha de respostas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!wget --no-check-certificate --content-disposition https://raw.githubusercontent.com/vanderlei-test/dataset-3/master/to_be_scored.csv\n",
    "df_to_be_scored = pd.read_csv(r'to_be_scored.csv')\n",
    "df_to_be_scored.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção!\n",
    "\n",
    "O dataframe ``to_be_scored`` é a sua \"folha de respostas\". Note que a coluna \"categoria\" não existe nessa amostra, que não pode ser então utilizada para treino de modelos de aprendizado supervisionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_to_be_scored.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Atenção!\n",
    "\n",
    "# Para poder aplicar seu modelo e classificar a folha de respostas, você precisa primeiro aplicar as mesmas transformações com colunas que você aplicou no dataset de treino.\n",
    "\n",
    "# Não remova ou adicione linhas na folha de respostas. \n",
    "\n",
    "# Não altere a ordem das linhas na folha de respostas.\n",
    "\n",
    "# Ao final, as 1000 entradas devem estar classificadas, com os valores previstos em uma coluna chamada \"target\"\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na célula abaixo, repetimos rapidamente os mesmos passos de pré-processamento usados no exemplo dado com árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Removendo linhas com valores NaN em \"certificados\" e \"total_modulos\"\n",
    "df_to_be_scored_1 = df_to_be_scored.dropna(axis='index', how='any', subset=['certificados', 'total_modulos'])\n",
    "\n",
    "# 2 - Inputando zeros nos valores faltantes\n",
    "impute_zeros.fit(X=df_to_be_scored_1)\n",
    "df_to_be_scored_2 = pd.DataFrame.from_records(\n",
    "    data=impute_zeros.transform(\n",
    "        X=df_to_be_scored_1\n",
    "    ),\n",
    "    columns=df_to_be_scored_1.columns\n",
    ")\n",
    "\n",
    "# 3 - Remoção de colunas\n",
    "df_to_be_scored_3 = df_to_be_scored_2.drop(columns=['id', 'graduacao', 'universidade', 'organizacao', 'como_conheceu_lit'], inplace=False)\n",
    "\n",
    "# 4 - Encoding com \"dummy variables\"\n",
    "df_to_be_scored_4 = pd.get_dummies(df_to_be_scored_3, columns=['profissao'])\n",
    "\n",
    "df_to_be_scored_4.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Pode ser verificado abaixo que as colunas da folha de resposta agora são idênticas às que foram usadas para treinar o modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training[\n",
    "    [\n",
    "        'pretende_fazer_cursos_lit', 'interesse_mba_lit',\n",
    "        'importante_ter_certificado', 'horas_semanais_estudo', 'total_modulos',\n",
    "        'modulos_iniciados', 'modulos_finalizados', 'certificados',\n",
    "        'profissao_0', 'profissao_Advogado', 'profissao_Analista',\n",
    "        'profissao_Analista Senior', 'profissao_Assessor',\n",
    "        'profissao_Coordenador', 'profissao_Diretor', 'profissao_Engenheiro',\n",
    "        'profissao_Gerente', 'profissao_Outros', 'profissao_SEM EXPERIÊNCIA',\n",
    "        'profissao_Supervisor', 'profissao_Sócio/Dono/Proprietário'\n",
    "    ]\n",
    "].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_be_scored_4.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção\n",
    "\n",
    "Para todas colunas que não existirem no \"df_to_be_scored\", você pode usar a técnica abaixo para adicioná-las:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_be_scored_4['profissao_0'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = dtc.predict(df_to_be_scored_4)\n",
    "df_to_be_scored_4['target'] = y_pred\n",
    "df_to_be_scored_4.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando a folha de respostas como um arquivo .csv para ser submetido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save_data(file_name=\"results.csv\", data=df_to_be_scored_4.to_csv(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção\n",
    "\n",
    "# A execução da célula acima irá criar um novo \"data asset\" no seu projeto no Watson Studio. Você precisará realizar o download deste arquivo juntamente com este notebook e criar um arquivo zip com os arquivos **results.csv** e **notebook.ipynb** para submissão. (os arquivos devem estar nomeados desta forma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Parabéns!\n",
    "\n",
    "Se você já está satisfeito com a sua solução, vá até a página abaixo e envie os arquivos necessários para submissão.\n",
    "\n",
    "# https://lit.maratona.dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
