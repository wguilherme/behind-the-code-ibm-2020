{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "# MARATONA BEHIND THE CODE 2020\n\n## DESAFIO 2: PARTE 1"}, {"metadata": {}, "cell_type": "code", "source": "# Primeiro, realizamos a instala\u00e7\u00e3o do scikit-learn vers\u00e3o 0.20.0 no Kernel deste notebook:\n!pip install scikit-learn==0.20.0 --upgrade", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Collecting scikit-learn==0.20.0\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/b2/05be9b6da9ae4a4c54f537be22e95833f722742a02b1e355fdc09363877c/scikit_learn-0.20.0-cp36-cp36m-manylinux1_x86_64.whl (5.3MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5.3MB 5.9MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.8.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-learn==0.20.0) (1.15.4)\nRequirement already satisfied, skipping upgrade: scipy>=0.13.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-learn==0.20.0) (1.2.0)\n\u001b[31mERROR: autoai-libs 1.10.5 has requirement numpy>=1.16.4, but you'll have numpy 1.15.4 which is incompatible.\u001b[0m\n\u001b[31mERROR: autoai-libs 1.10.5 has requirement pandas>=0.24.2, but you'll have pandas 0.24.1 which is incompatible.\u001b[0m\n\u001b[31mERROR: autoai-libs 1.10.5 has requirement scikit-learn==0.20.3, but you'll have scikit-learn 0.20.0 which is incompatible.\u001b[0m\nInstalling collected packages: scikit-learn\n  Found existing installation: scikit-learn 0.20.3\n    Uninstalling scikit-learn-0.20.3:\n      Successfully uninstalled scikit-learn-0.20.3\nSuccessfully installed scikit-learn-0.20.0\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# Em seguida iremos importar diversas bibliotecas que ser\u00e3o utilizadas:\n\n# Pacote para trabalhar com JSON\nimport json\n\n# Pacote para realizar requisi\u00e7\u00f5es HTTP\nimport requests\n\n# Pacote para explora\u00e7\u00e3o e an\u00e1lise de dados\nimport pandas as pd\n\n# Pacote com m\u00e9todos num\u00e9ricos e representa\u00e7\u00f5es matriciais\nimport numpy as np\n\n# Pacote para constru\u00e7\u00e3o de modelo baseado na t\u00e9cnica Gradient Boosting\n# import xgboost as xgb\n\n# Pacotes do scikit-learn para pr\u00e9-processamento de dados\n# \"SimpleImputer\" \u00e9 uma transforma\u00e7\u00e3o para preencher valores faltantes em conjuntos de dados\n# from sklearn.impute import SimpleImputer\n\n# Pacotes do scikit-learn para treinamento de modelos e constru\u00e7\u00e3o de pipelines\n# M\u00e9todo para separa\u00e7\u00e3o de conjunto de dados em amostras de treino e teste\nfrom sklearn.model_selection import train_test_split\n# M\u00e9todo para cria\u00e7\u00e3o de modelos baseados em \u00e1rvores de decis\u00e3o\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Classe para a cria\u00e7\u00e3o de uma pipeline de machine-learning\nfrom sklearn.pipeline import Pipeline\n\n# Pacotes do scikit-learn para avalia\u00e7\u00e3o de modelos\n# M\u00e9todos para valida\u00e7\u00e3o cruzada do modelo criado\nfrom sklearn.model_selection import KFold, cross_validate", "execution_count": 2, "outputs": []}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_6bf00ac4974d4ebca29366046002b022 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='4yY1TWGH3RZDX2x5JUZGF15dDiPziZOeoJVqmOwbynrM',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n\nbody = client_6bf00ac4974d4ebca29366046002b022.get_object(Bucket='desafio2maratona2020-donotdelete-pr-f8f9ytipcxxarm',Key='dataset_desafio_2.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf_data = pd.read_csv(body)\n", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_data.drop(labels=['NOME','INGLES','MATRICULA','H_AULA_PRES','TAREFAS_ONLINE'],axis=1,inplace=True)\ndf_data.head()", "execution_count": 4, "outputs": [{"output_type": "execute_result", "execution_count": 4, "data": {"text/plain": "   REPROVACOES_DE  REPROVACOES_EM  REPROVACOES_MF  REPROVACOES_GO  NOTA_DE  \\\n0               0               0               0               0      6.2   \n1               0               0               0               0      6.0   \n2               0               0               0               0      7.3   \n3               1               3               1               1      0.0   \n4               1               3               1               1      0.0   \n\n   NOTA_EM  NOTA_MF  NOTA_GO  FALTAS       PERFIL  \n0      5.8      4.6      5.9       3       EXATAS  \n1      6.2      5.2      4.5       3       EXATAS  \n2      6.7      7.1      7.2       3      HUMANAS  \n3      0.0      0.0      0.0       4  DIFICULDADE  \n4      0.0      0.0      0.0       5  DIFICULDADE  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>REPROVACOES_DE</th>\n      <th>REPROVACOES_EM</th>\n      <th>REPROVACOES_MF</th>\n      <th>REPROVACOES_GO</th>\n      <th>NOTA_DE</th>\n      <th>NOTA_EM</th>\n      <th>NOTA_MF</th>\n      <th>NOTA_GO</th>\n      <th>FALTAS</th>\n      <th>PERFIL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6.2</td>\n      <td>5.8</td>\n      <td>4.6</td>\n      <td>5.9</td>\n      <td>3</td>\n      <td>EXATAS</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6.0</td>\n      <td>6.2</td>\n      <td>5.2</td>\n      <td>4.5</td>\n      <td>3</td>\n      <td>EXATAS</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.3</td>\n      <td>6.7</td>\n      <td>7.1</td>\n      <td>7.2</td>\n      <td>3</td>\n      <td>HUMANAS</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>DIFICULDADE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5</td>\n      <td>DIFICULDADE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#IGNORANDO COLUNA NOTA_GO // 71.5%\n# df_data.drop(labels=['NOTA_GO'],axis=1,inplace=True)\n\n#REMOVER LINHAS COM VALORES NULL // 71.8%\ndf_data.dropna(inplace=True)\n\n#PREENCHENDO VALORES NULL COM 0 // 72.1%\n# df_data.fillna(value=0,axis=0,inplace=True)\n\n#PREENCHENDO VALORES NULL COM NOTA_GO.MEDIA() // 72.4%\n# df_data.fillna(value=df_data['NOTA_GO'].mean(),axis=0,inplace=True)\n\n#PREENCHENDO VALORES NULL COM NOTA_GO.MODE()\n# df_data.fillna(value=df_data['NOTA_GO'].mode(),axis=0,inplace=True)\n\n#PREENCHENDO VALORES NULL COM NOTA_GO.MEDIAN() // 71.2%\n# df_data.fillna(value=df_data['NOTA_GO'].median(),axis=0,inplace=True)\n\n#PREENCHENDO VALORES NULL COM MEDIA() DAS OUTRAS NOTAS // 72.2%\n# df_data.loc[df_data['NOTA_GO'].isnull(),'NOTA_GO'] = (df_data.loc[df_data['NOTA_GO'].isnull(),'NOTA_DE'] + df_data.loc[df_data['NOTA_GO'].isnull(),'NOTA_EM'] + df_data.loc[df_data['NOTA_GO'].isnull(),'NOTA_MF'])/3\n\n# df_data.drop(labels=['NOTA_GO'],axis=1,inplace=True)\n# df_data['NOTA_GO'] = (df_data['NOTA_DE']+df_data['NOTA_EM']+df_data['NOTA_MF'])/3\n# df_data = df_data[['REPROVACOES_DE', 'REPROVACOES_EM', 'REPROVACOES_MF', 'REPROVACOES_GO', 'NOTA_DE', 'NOTA_EM', 'NOTA_MF', 'NOTA_GO', 'PERFIL']]\n\ndf_data['MEDIA'] = (df_data['NOTA_DE']+df_data['NOTA_EM']+df_data['NOTA_MF']+df_data['NOTA_GO'])/4\ndf_data = df_data[['REPROVACOES_DE', 'REPROVACOES_EM', 'REPROVACOES_MF', 'REPROVACOES_GO', 'NOTA_DE', 'NOTA_EM', 'NOTA_MF', 'NOTA_GO', 'MEDIA', 'FALTAS', 'PERFIL']]\n", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#class_weight para o modelo\n#{'REPROVACOES_DE':1,'REPROVACOES_EM':1,'REPROVACOES_MF':1,'REPROVACOES_GO':1,'NOTA_DE':2,'NOTA_EM':2,'NOTA_MF':4,'NOTA_GO':2,'MEDIA':3,'FALTAS':1}\n# [{'REPROVACOES_DE':1}, {'REPROVACOES_EM':1}, {'REPROVACOES_MF':1}, {'REPROVACOES_GO':1}, {'NOTA_DE':2}, {'NOTA_EM':2}, {'NOTA_MF':4}, {'NOTA_GO':2}, {'MEDIA':3}, {'FALTAS':1}]", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Prepara\u00e7\u00e3o dos argumentos para os m\u00e9todos da biblioteca ``scikit-learn``\nX = df_data[df_data.columns[:len(df_data.columns)-1]]\ny = df_data[\"PERFIL\"]", "execution_count": 7, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Separa\u00e7\u00e3o dos dados em um conjunto de treino e um conjunto de teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=337)", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Cria\u00e7\u00e3o da \u00e1rvore de decis\u00e3o com a biblioteca ``scikit-learn``:\n# dtc_model = DecisionTreeClassifier(random_state=100,max_depth=3)  # O modelo ser\u00e1 criado com os par\u00e2metros padr\u00f5es da biblioteca\nrfc_model = RandomForestClassifier(max_depth=6, n_estimators=200, max_features='auto')\n\n", "execution_count": 15, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Treino do modelo (\u00e9 chamado o m\u00e9todo *fit()* com os conjuntos de treino)\n# dtc_model.fit(\n#     X_train,\n#     y_train\n# )\n\nrfc_model.fit(\n    X_train,\n    y_train\n)\n", "execution_count": 16, "outputs": [{"output_type": "execute_result", "execution_count": 16, "data": {"text/plain": "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=6, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# Realiza\u00e7\u00e3o de teste cego no modelo criado\n# y_pred = dtc_model.predict(X_test)\ny_pred = rfc_model.predict(X_test)\n", "execution_count": 17, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.metrics import accuracy_score\n\n# Acur\u00e1cia alcan\u00e7ada pela \u00e1rvore de decis\u00e3o\nprint(\"Acur\u00e1cia: {:.2f}%\".format(100*accuracy_score(y_test, y_pred)))", "execution_count": 18, "outputs": [{"output_type": "stream", "text": "Acur\u00e1cia: 81.62%\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}